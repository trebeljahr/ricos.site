---
title: "100k Token Contexts, AI Tutors and Google/IO"
cover:
    src: "/assets/midjourney/majestic-waterfall-cascading-into-a-clear-turquoise-pond.jpg"
    alt: "majestic waterfall cascading into a clear turquoise pond"
    width: 780
    height: 780
excerpt: "Welcome to this edition of Live and Learn. This time it's one of those editions again where the amount of things that have happened in the last two weeks is simply incomprehensible. I already cut out so much that I would like to include and still this edition grew beyond the 4-5 links that I try to set myself as a limit. AI is moving at an ever-accelerating pace and the more I read the more I get a feeling for what this means. I still have over 100 tabs bookmarked that I won't get to read in time before I bookmark the next 100. And this to me is insane. It feels great to dig into all that is happening but also overwhelming. Anyways. This edition has insights from the GoogleIO, a great article about how open source is taking over LLTMs by storm, and an exploration of the music generation capabilities of ChatGPT."
tags: ["AI", "progress", "future", "Segmentation", "Software¬≤"]
---

## ‚ú® Quote ‚ú®



## üñáÔ∏è Links üñáÔ∏è

[**GPT-4 explains GPT-2** by OpenAI](https://openai.com/research/language-models-can-explain-neurons-in-language-models). 

[**Introducing 100k Context Windows** by Anthropic](https://www.anthropic.com/index/100k-context-windows). You can now officially feed LLTMs with entire books worth of prompts in one go. This still blows my mind, I mean seriously, 100k tokens is around 75k words, which is literally? Imagine you had somebody that could read and summarize all of Harry Potter and the Philosopher's Stone (76944 words) in a little less than a minute. Now stop imagining it because well, we have the technology to do that. And it's only going to get crazier from here on out.

[**We have No Moat** by SemiAnalysis](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither). This article argues that open source is starting to dominate over OpenAI and Google's efforts and that these companies should embrace the open source culture. The examples in it alone are worth reading. And the timeline at the end really shows how fast things move once people get their hands on models to play around with and iterate over. Within days the world of research around LLTMs is changing and the main catalyst for the change is open source. 

[**Google I/O Keynote** by Google](https://youtu.be/cNfINi5CNbY). I've watched the entire Google Keynote sessions for quite some years now and they never cease to amaze me. However, that being said, with the current rate of progress in AI development this keynote felt a bit lackluster. It's weird to see Google playing catch-up with AI and trying to convince the world that they are a powerhouse within AI research and AI operations. 

[**Mr. Ranedeer** by JushBJJ](https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor). One of the coolest personalized AI tutors I have seen. With it, you can learn pretty much anything, really quickly. This feels like magic because people are coming up with exact ways of configuring these models to solve very specific tasks. This is what "prompt engineering" really means. Copy-pasting the prompt and being greeted exactly what was predicted is simply and utterly mindblowing. If you want to learn *anything* I think this is one of the best ways out there today and I am happy to explore it more in the coming weeks.

[**But can ChatGPT-4 write a good melody?** by Marc Evanstein](https://www.youtube.com/watch?v=d_7EsKcn8nw). This is an exploration of using GPT-4, a *language* model, to create music. Right now GPT-4 is not great at it. But if you stop for a second and think about what it is actually doing it is *extremely* good for being "only" a large language model. You have to keep in mind that it has never learned the rules of music. It doesn't even have a concept of sound as such or can hear what it proposes as compositions... I mean, seriously, imagine somebody who has never heard music in their life composing a piece of classical music and actually doing a pretty decent job at it... I mean heck, most people I know of couldn't even do all of the tasks proposed to the GPT-4 model, and I would bet that even some musicians would struggle with what GPT-4 does in this video.

## üåå Midjourney üåå

![person exploring a volcano on an alien planet](/assets/midjourney/person-exploring-a-volcano-on-an-alien-planet.jpg)
![a photorealistic image of a rugged cliff with a beautiful woman in a red dress standing on top](/assets/midjourney/a-photorealistic-image-of-a-rugged-cliff-with-a-beautiful-woman-in-a-red-dress-standing-on-top.jpg)
![an explorer studying the wildlife on a marine exoplanet](/assets/midjourney/an-explorer-studying-the-wildlife-on-a-marine-exoplanet.jpg)
![a hiker exploring a field of flowers in the mountains](/assets/midjourney/a-hiker-exploring-a-field-of-flowers-in-the-mountains.jpg)



## üé∂ Song üé∂

**Moonlight Sonata, 3rd Movement** by Beethoven

[Youtube Music](https://music.youtube.com/watch?v=BV7RkEL6oRc) | [Spotify](https://open.spotify.com/track/6jBT9MBVjX4kZ68IV6wHnH)

---

I hope you found this newsletter useful, beautiful, or even both!

Have ideas for improving it? [Please let me know](https://airtable.com/shro1VeyG4lkNXkx2).

Cheers,

**‚Äì Rico**

